{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66bcab0f-8b39-4585-b97f-32b3827a1b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a keyword or phrase to focus your search:  bitcoin \n",
      "Please enter the number of Tweets you would like to analyse:  10\n",
      "How many of the last days would you like to analyse?:   2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-12-22', '2022-12-23']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import nltk\n",
    "import sys\n",
    "from textblob import TextBlob\n",
    "import snscrape\n",
    "import datetime\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "sns.kdeplot(data=df_comp, fill=True)\n",
    "\n",
    "\n",
    "\n",
    "keyword = (input(\"Please enter a keyword or phrase to focus your search: \"))\n",
    "NoOfTweets = int(input(\"Please enter the number of Tweets you would like to analyse: \"))\n",
    "days = int(input(\"How many of the last days would you like to analyse?:  \"))\n",
    "\n",
    "tweet_list = []\n",
    "dates = []\n",
    "                                       \n",
    "# Loop through the last 150 days\n",
    "for i in range(days):\n",
    "  # Calculate the date for the current iteration\n",
    "    date = datetime.datetime.now() - datetime.timedelta(days=i)\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "\n",
    "  # Add the date to the list of dates\n",
    "    dates.append(date_str)\n",
    "    \n",
    "dates = dates[::-1]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df15c76c-5da3-43f7-bdc3-52ab43ecd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('@[A-Za-z0–9]+', '', text) #Removing @mentions\n",
    "    text = re.sub('#', '', text) # Removing '#' hash tags\n",
    "    text = re.sub('RT[\\s]+', '', text) # Removing RTs\n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlinks\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'_', '', text) # Remove underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ee38eb-e20c-42d8-8372-88cb0d35c1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a keyword or phrase to focus your search:  bitcoin \n",
      "Please enter the number of Tweets you would like to analyse:  100\n",
      "How many of the last days would you like to analyse?:   150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n",
      "One day done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mean reply count</th>\n",
       "      <th>Mean retweet count</th>\n",
       "      <th>Mean like count</th>\n",
       "      <th>Mean sentiment of daily tweets</th>\n",
       "      <th>Mean subjectivity of daily tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.45</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0.090086</td>\n",
       "      <td>0.03551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.095715</td>\n",
       "      <td>0.02793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.45</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.197435</td>\n",
       "      <td>0.07136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.039936</td>\n",
       "      <td>0.02172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.117555</td>\n",
       "      <td>0.03762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Keyword        Date  Mean reply count  Mean retweet count  \\\n",
       "0  bitcoin   2022-07-28              1.24                1.45   \n",
       "1  bitcoin   2022-07-29              0.88                0.76   \n",
       "2  bitcoin   2022-07-30              1.42                1.45   \n",
       "3  bitcoin   2022-07-31              1.00                0.31   \n",
       "4  bitcoin   2022-08-01              0.74                0.36   \n",
       "\n",
       "   Mean like count  Mean sentiment of daily tweets  \\\n",
       "0            10.16                        0.090086   \n",
       "1             3.74                        0.095715   \n",
       "2             7.00                        0.197435   \n",
       "3             3.05                        0.039936   \n",
       "4             2.69                        0.117555   \n",
       "\n",
       "   Mean subjectivity of daily tweets  \n",
       "0                            0.03551  \n",
       "1                            0.02793  \n",
       "2                            0.07136  \n",
       "3                            0.02172  \n",
       "4                            0.03762  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import nltk\n",
    "import sys\n",
    "from textblob import TextBlob\n",
    "import snscrape\n",
    "import datetime\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns \n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('@[A-Za-z0–9]+', '', text) #Removing @mentions\n",
    "    text = re.sub('#', '', text) # Removing '#' hash tags\n",
    "    text = re.sub('RT[\\s]+', '', text) # Removing RTs\n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlinks\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'_', '', text) # Remove underscores\n",
    "    \n",
    "    return text \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dates = []\n",
    "\n",
    "mean_sentiment_list = []\n",
    "mean_subjectivity_list = []\n",
    "\n",
    "whole_data = []\n",
    "mean_reply_count_list = []\n",
    "mean_retweet_count_list = []\n",
    "mean_like_count_list = []\n",
    "\n",
    "keyword = (input(\"Please enter a keyword or phrase to focus your search: \"))\n",
    "NoOfTweets = int(input(\"Please enter the number of Tweets you would like to analyse: \"))\n",
    "days = int(input(\"How many of the last days would you like to analyse?:  \"))\n",
    "\n",
    "# Create empty data frames to store the mean sentiment and subjectivity scores for each day for each keyword\n",
    "df_bitcoin = pd.DataFrame(columns=['date', 'mean_sentiment', 'mean_subjectivity', 'price'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loop through the last 150 days\n",
    "for i in range(days):\n",
    "  # Calculate the date for the current iteration\n",
    "    start = datetime.datetime.now() - datetime.timedelta(days=i)\n",
    "    end = datetime.datetime.now() - datetime.timedelta(days=(i-1 ))\n",
    "    date_str = start.strftime('%Y-%m-%d')\n",
    "\n",
    "  # Add the date to the list of dates\n",
    "    dates.append(date_str)\n",
    "    \n",
    "dates = dates[::-1]\n",
    "\n",
    "    \n",
    "    \n",
    "for date in dates:\n",
    "    sentiment_scores = []\n",
    "    subjectivity_scores = []\n",
    "    \n",
    "    tweet_list = []\n",
    "    like_count_list = []\n",
    "    reply_count_list = []\n",
    "    retweet_count_list = []\n",
    "    \n",
    "    # print(date)\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{keyword} lang:en until:{date}').get_items()):\n",
    "        if i>=NoOfTweets:\n",
    "            break \n",
    "        whole_data.append([tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.replyCount, tweet.retweetCount, tweet.likeCount])\n",
    "        tweet_list.append(tweet.rawContent)\n",
    "        like_count_list.append(tweet.likeCount)\n",
    "        reply_count_list.append(tweet.replyCount)\n",
    "        retweet_count_list.append(tweet.retweetCount)\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    for tweet in tweet_list:\n",
    "        tweet = clean_text(tweet)\n",
    "        \n",
    "        analyser = SentimentIntensityAnalyzer()\n",
    "        scores = analyser.polarity_scores(tweet)\n",
    "        sentiment_scores.append(scores['compound'])\n",
    "        subjectivity_scores.append(scores['pos'] - scores['neg'])\n",
    "        \n",
    "    # print(sentiment_scores)\n",
    "        \n",
    "        # Calculate the mean sentiment and subjectivity scores for the day\n",
    "    mean_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
    "    mean_sentiment_list.append(mean_sentiment)\n",
    "\n",
    "    mean_subjectivity = sum(subjectivity_scores) / len(subjectivity_scores)\n",
    "    mean_subjectivity_list.append(mean_subjectivity)\n",
    "    \n",
    "    mean_like_count = sum(like_count_list) / len(like_count_list)\n",
    "    mean_like_count_list.append(mean_like_count)\n",
    "    \n",
    "    mean_reply_count = sum(reply_count_list) / len(reply_count_list)\n",
    "    mean_reply_count_list.append(mean_reply_count)\n",
    "\n",
    "    mean_retweet_count = sum(retweet_count_list) / len(retweet_count_list)\n",
    "    mean_retweet_count_list.append(mean_retweet_count)\n",
    "\n",
    "    \n",
    "\n",
    "    print('One day done!')\n",
    "\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(whole_data)\n",
    "df.columns = ['Date', 'ID', 'Text', 'Username', 'Reply count', 'Retweet count', 'Like count']\n",
    "df.to_csv(f'{keyword}_raw_extracted_data.csv', index = False)\n",
    "#     print(tweet_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# print(mean_sentiment_list)\n",
    "\n",
    "        \n",
    "\n",
    "keyword_list = [f'{keyword}']*150\n",
    "\n",
    "# Add the mean sentiment, subjectivity, and price information to the data frame for bitcoin\n",
    "df1 = pd.Series(keyword_list, name = 'Keyword')\n",
    "df2 = pd.Series(dates, name = 'Date')\n",
    "df3 = pd.Series(mean_reply_count_list, name = 'Mean reply count')\n",
    "df4 = pd.Series(mean_retweet_count_list, name = 'Mean retweet count')\n",
    "df5 = pd.Series(mean_like_count_list, name = 'Mean like count')\n",
    "df6 = pd.Series(mean_sentiment_list, name = 'Mean sentiment of daily tweets')\n",
    "df7 = pd.Series(mean_subjectivity_list, name = 'Mean subjectivity of daily tweets')\n",
    "\n",
    "\n",
    "\n",
    "df_bitcoin = pd.concat([df1, df2, df3, df4, df5, df6, df7], axis = 1)\n",
    "\n",
    "df_bitcoin.to_csv(f'Formatted_{keyword}_questions_data.csv', index = False)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "df_bitcoin.head()\n",
    "\n",
    "# sns.lineplot(x = 'Date', y = 'Mean sentiment of daily tweets', data = df_bitcoin).set(xlabel = 'Date', ylabel = 'Mean sentiment over select tweets of given day')\n",
    "\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# df_bitcoin.to_csv(f'{keyword}_SDPA_pt2.csv', index = False)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "# for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{keyword} lang:en since:2022-12-23until:2022-12-23').get_items()):\n",
    "#     if i>=NoOfTweets:\n",
    "#         break\n",
    "#     tweet_list.append([tweet.rawContent])\n",
    "    \n",
    "    \n",
    "# df = pd.DataFrame(tweet_list, columns=['Text'])\n",
    "# df.head()\n",
    "        \n",
    "        \n",
    "\n",
    "                \n",
    "                \n",
    "               \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61660684-472e-4c13-94fe-8b430cf818bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ea882-f8f1-46bd-b6bc-d6a8c8614fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a70672-2b00-40dc-b6a2-eb4e4b77c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da2783-eefc-4e3c-b19b-c9a448ccc52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
